{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TwitterAPI For Users Description.ipynb","provenance":[],"authorship_tag":"ABX9TyMJ4+o6WYMIbDV5jjSW+ZgG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Installs and Imports"],"metadata":{"id":"xt_Zgaf7Etwr"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dn38_SXdEgip"},"outputs":[],"source":["! pip install requests\n","! pip install requests-oauthlib\n","! pip install wordcloud"]},{"cell_type":"markdown","source":["## Mounting GDrive"],"metadata":{"id":"IvQIu9IJE0RE"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Uc1OdjCvE5FM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"JObZXsjGE9wO"}},{"cell_type":"code","source":["import requests\n","import os\n","import json\n","import numpy as np\n","import pandas as pd\n","import time\n","import json"],"metadata":{"id":"v-b5nC6NE-77"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# API token environment variables definition\n","\n","This notebook uses the Twitter API V2 for developers. To use it you must have a developer account.\n","To open a developer account, and see more details, visit the following URL:\n","https://developer.twitter.com/en/docs/twitter-api\n"],"metadata":{"id":"c26ux8KHFBdF"}},{"cell_type":"code","source":["! export API_KEY = 'YOUR_API_KEY' # replace with your API key\n","! export API_KEY_SECRET = 'YOUR_API_SECRET' # replace with your API Secret\n","! export BEARER_TOKEN = 'YOUR_BEARER_TOKEN' # replace with your Bearer token"],"metadata":{"id":"xLiKoVicFOC7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Quering our non-trolls users' descriptions"],"metadata":{"id":"IzACZLTbFOUA"}},{"cell_type":"markdown","source":["## getting the non-trolls users' ids from IRA dataset"],"metadata":{"id":"zWvwD6MZGNhw"}},{"cell_type":"code","source":["path_to_preprocessed_data_dir = '/content/drive/MyDrive/NLP_And_Social_Dynamics/Data/preprocessed_data' #replace with the path to your joined file directory\n","user_ids_fname = 'joined_users_dataset.csv' # replace with your joined filename (if necessary)\n","path_to_users_ids_df = os.path.join(path_to_preprocessed_data_dir, user_ids_fname)"],"metadata":{"id":"nx4wgQKiGR-X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# only non-trolls users:\n","non_trolls_df = users_ids_df[users_ids_df['target_type'].isna()]\n","non_trolls_user_ids = non_trolls_df['target_id']\n","non_trolls_df.head()"],"metadata":{"id":"kG2LIL8vGeq4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# non-troll users unique ids\n","non_trolls_unique_user_ids = np.unique(non_trolls_user_ids.values)"],"metadata":{"id":"PAqvY9XKGhZW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## API queries functions:"],"metadata":{"id":"lXb-OvvxGqZY"}},{"cell_type":"markdown","source":["### Query single user description"],"metadata":{"id":"6-k3w4BKG91H"}},{"cell_type":"code","source":["\n","bearer_token = 'YOUR_BEARER_TOKEN' # replace with your Bearer token\n","\n","def create_url(**kwargs):\n","    # List fields are adjustable, options include:\n","    # created_at, description, owner_id,\n","    # private, follower_count, member_count,\n","    list_fields = f\"list.fields={kwargs.get('list.fields', 'created_at,follower_count')}\"\n","    # You can replace the ID given with the List ID you wish to lookup.\n","    id = kwargs.get('users_ids_to_retrieve', [])\n","    \n","    url = \"https://api.twitter.com/2/lists/{}\".format(id)\n","    return url, list_fields\n","\n","\n","def bearer_oauth(r):\n","    \"\"\"\n","    Method required by bearer token authentication.\n","    \"\"\"\n","\n","    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n","    r.headers[\"User-Agent\"] = \"v2ListLookupPython\"\n","    return r\n","\n","\n","def connect_to_endpoint(url, list_fields, ids=[]):\n","    response = requests.request(\"GET\", url, auth=bearer_oauth, params=list_fields)\n","    # print(response.status_code)\n","    if response.status_code != 200:\n","        raise Exception(\n","            \"Request returned an error: {} {}\\n{}\".format(\n","                response.status_code, response.text, response\n","            )\n","        )\n","    return response.json()\n","\n","\n","def get_users_attributes_by_ids(**kwargs):\n","    url, list_fields = create_url(**kwargs)\n","    json_response = connect_to_endpoint(url, list_fields)\n","    \n","    return json_response"],"metadata":{"id":"fJ-fyLvGHGp9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### usage example"],"metadata":{"id":"HXaYiKZnHSIc"}},{"cell_type":"code","source":["non_trolls_validity_df = pd.DataFrame(columns=['uid', 'isValid', 'errors'])\n","\n","for idx, non_troll_uid in enumerate(non_trolls_unique_user_ids):\n","  if non_troll_uid in non_trolls_validity_df['uid'].values:\n","    continue\n","  u_api_response = get_users_attributes_by_ids(users_ids_to_retrieve=non_troll_uid)\n","  errors = u_api_response.get('errors', None)\n","  if errors is not None:\n","    is_valid = u_api_response['errors'][0].get('title', '')!='Not Found Error'\n","  else:\n","    errors = ''\n","    is_valid = True\n","  \n","  non_trolls_validity_df.loc[idx, :] = [non_troll_uid, is_valid, errors]"],"metadata":{"id":"2QnY1AXPHV3A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Query description for users in batches:"],"metadata":{"id":"qU-m57-jHfTC"}},{"cell_type":"code","source":["import requests\n","import os\n","import json\n","\n","bearer_token = 'YOUR_BEARER_TOKEN' # replace with your Bearer token\n","\n","\n","def create_url(users_ids: np.ndarray = []):\n","    # Specify the usernames that you want to lookup below\n","    # You can enter up to 100 comma-separated values.\n","    usernames = f'usernames={\",\".join(users_ids)}'\n","    # usernames = \"usernames=TwitterDev,TwitterAPI\"\n","    user_fields = \"user.fields=description,created_at\"\n","    # User fields are adjustable, options include:\n","    # created_at, description, entities, id, location, name,\n","    # pinned_tweet_id, profile_image_url, protected,\n","    # public_metrics, url, username, verified, and withheld\n","    url = \"https://api.twitter.com/2/users/by?{}&{}\".format(usernames, user_fields)\n","    return url\n","\n","\n","def bearer_oauth(r):\n","    \"\"\"\n","    Method required by bearer token authentication.\n","    \"\"\"\n","\n","    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n","    r.headers[\"User-Agent\"] = \"v2UserLookupPython\"\n","    return r\n","\n","\n","def connect_to_endpoint(url):\n","    response = requests.request(\"GET\", url, auth=bearer_oauth,)\n","    return response.status_code, response.json(), \n","\n","\n","def batch_users_lookup(**kwargs):\n","    url = create_url(**kwargs)\n","    res_status_code, json_response = connect_to_endpoint(url)\n","    return res_status_code, json_response\n","\n"],"metadata":{"id":"OxtRvvmgHlFm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Usage example\n","Due to the limits on queries per time periods, the code reads an exsiting dataframe from last runs (if exists, if not, creates an empty one). \n","Then, in batches of 100 users (with time delay intervals between each batch), if some users ids are not in the existing dataframe, their descriptions are queried from the twitter API and concatenated to the existing dataframe. At the end of each batch, the dataframe is saved to GDrive to prevent loss of aggregated information. \n","If the Twitter API returns an error that indicates the developer reached its temporary query limit, an appropriate error is printed to the console."],"metadata":{"id":"xwUcYoeMHlds"}},{"cell_type":"code","source":["path_to_non_trolls_validity_df = '/content/drive/MyDrive/NLP_And_Social_Dynamics/Data/non_trolls_u_description.csv'\n","if os.path.isfile(path_to_non_trolls_validity_df):\n","  non_trolls_validity_df = pd.read_csv(path_to_non_trolls_validity_df)\n","else:  \n","  non_trolls_validity_df = pd.DataFrame(columns=['uid', 'isValid', 'Repsonse'])\n","\n","non_trolls_validity_df = non_trolls_validity_df.set_index('uid', verify_integrity=True)"],"metadata":{"id":"etkBDJleHnPo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 100\n","\n","for batch_idx in np.arange(0, len(non_trolls_unique_user_ids)+999, batch_size):\n","  if batch_idx > len(non_trolls_unique_user_ids):\n","    break\n","\n","  non_troll_uids = non_trolls_unique_user_ids[batch_idx: batch_idx+batch_size]\n","  if len(non_troll_uids)>100:\n","    print(len(non_troll_uids))\n","  if all([x in non_trolls_validity_df['uid'].values for x in non_troll_uids]):\n","    continue\n","  res_status_code, u_api_response = batch_users_lookup(users_ids=non_troll_uids)\n","  if res_status_code == 429:\n","    print(f'ran out of requests on UID idx: {batch_idx}')\n","    non_trolls_validity_df.to_csv(path_to_non_trolls_validity_df)\n","    break\n","  errors = u_api_response.get('errors', None)\n","  if errors is not None:\n","    uids_not_found = []\n","    for er in errors:\n","      uid_not_found = er.get('value', None) if 'could not find user' in er.get('detail', '').lower() else None\n","      if uid_not_found is not None:\n","        uids_not_found.append(uid_not_found)\n","    # print(errors)\n","    # print(u_api_response)\n","    if uids_not_found:\n","      uids_not_found = uids_not_found[0].split(',')\n","      are_valid = pd.DataFrame({'uid': non_troll_uids, \n","                   'isValid': [uid not in uids_not_found for uid in non_troll_uids],\n","                   'Response': [u_api_response for uid in non_troll_uids]\n","                   })\n","      are_valid = are_valid.set_index('uid', verify_integrity=True)\n","  else:\n","    are_valid = pd.DataFrame({'uid': non_troll_uids, \n","                   'isValid': [True for uid in non_troll_uids],\n","                 'Response': [u_api_response for uid in non_troll_uids]\n","                   })\n","    are_valid = are_valid.set_index('uid', verify_integrity=True)\n","\n","  non_trolls_validity_df = pd.concat([non_trolls_validity_df,are_valid], axis=0)\n","  non_trolls_validity_df = non_trolls_validity_df.set_index('uid', verify_integrity=True)\n","  time.sleep(1)\n","\n","non_trolls_validity_df = non_trolls_validity_df[~non_trolls_validity_df.index.duplicated(keep='first')]\n","non_trolls_validity_df.to_csv(path_to_non_trolls_validity_df)\n","\n","print(f\"Reached {len(non_trolls_validity_df)}/{len(non_trolls_unique_user_ids)} users\")\n","if len(non_trolls_validity_df) == len(non_trolls_unique_user_ids):\n","  print(f\"DONE!!\")"],"metadata":{"id":"yFzY0NEAH4ig"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Transforming query results to parsed description"],"metadata":{"id":"VdCrmAGyJ5ZA"}},{"cell_type":"code","source":["df = non_trolls_validity_df.copy()\n","\n","descriptions_by_ids = {}\n","created_at_by_ids = {}\n","\n","\n","for row_idx, row in df.iterrows():\n","    response_dict = ast.literal_eval(row['Response'])\n","    u_data = response_dict.get('data', None)\n","    if u_data is None:\n","        continue\n","\n","    for data in u_data:\n","        d_uid = data['username']\n","        d_description = data['description']\n","        d_created_at = data['created_at']\n","        descriptions_by_ids[int(d_uid)] = d_description\n","        created_at_by_ids[int(d_uid)] = d_created_at\n","\n","non_trolls_with_description_df = pd.DataFrame(np.array([list(descriptions_by_ids.keys()), list(descriptions_by_ids.values()), list(created_at_by_ids.values())]).T , columns=['uid', 'description', 'created_at'])\n"],"metadata":{"id":"tqw7jvaYJ_cG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Calculating users with descriptions fraction and basic statistics"],"metadata":{"id":"nWc79lSqKS1t"}},{"cell_type":"code","source":["n_total_users = len(non_trolls_validity_df)\n","\n","df = non_trolls_with_description_df\n","\n","fig, axis = plt.subplots(figsize=(30,10))\n","u_with_empty_description = sum([x!=x for x in df['description']])\n","u_with_non_empty_description = sum([x!='' and x==x for x in df['description']])\n","\n","bars = axis.barh([0, 1], [u_with_empty_description, u_with_non_empty_description])\n","axis.set_yticks([0, 1])\n","axis.set_yticklabels(['#Users with empty description', '#Users with description'], rotation=45, fontsize=15)\n","for bar in bars:\n","    label = bar.get_width() / n_total_users\n","    axis.text(bar.get_width()+1,\n","              bar.get_y()+ bar.get_height()/2.,\n","              f\"{label:.5f}\", ha='center',\n","              fontsize=20,\n","              rotation=270)\n","\n","axis.set_title(f'Non Troll Users with description statistics\\nFraction from all Non Troll (#{n_total_users}) users (top of bar)', fontsize=30)\n","\n","plt.savefig('NonTrollsUsersWithDescriptionsCounts.jpg', dpi=200)\n","plt.show()"],"metadata":{"id":"riem-b-3KPJM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## WordCloud generation for aggregated descriptions:"],"metadata":{"id":"A8DeWJNrJJ-V"}},{"cell_type":"code","source":["from wordcloud import WordCloud, STOPWORDS\n","from typing import *\n"," \n","def show_wordcloud_for_text(text_raw_tokens: List[str], keep_stop_words:bool = False):\n","  comment_words = ''\n","  stopwords = set(STOPWORDS)\n","  \n","  # iterate through the csv file\n","  for val in df.CONTENT:\n","      \n","      # typecaste each val to string\n","      val = str(val)\n","  \n","      # split the value\n","      tokens = val.split()\n","      tokens = list(filter(lambda x: x.lower()!='nan', tokens))\n","      # Converts each token into lowercase\n","      for i in range(len(tokens)):\n","          tokens[i] = tokens[i].lower()\n","      \n","      comment_words += \" \".join(tokens)+\" \"\n","  \n","  wordcloud = WordCloud(width = 800, height = 800,\n","                  background_color ='white',\n","                  stopwords = stopwords if not keep_stop_words else None,\n","                  min_font_size = 10).generate(comment_words)\n"," \n","  # plot the WordCloud image                      \n","  plt.figure(figsize = (8, 8), facecolor = None)\n","  plt.imshow(wordcloud)\n","  plt.axis(\"off\")\n","  plt.tight_layout(pad = 0)\n","\n","# with stopwords included\n","show_wordcloud_for_text(df['description'].values.tolist(), keep_stop_words=True)\n","# with stopwords excluded\n","show_wordcloud_for_text(df['description'].values.tolist(), keep_stop_words=False)\n"],"metadata":{"id":"CfU4hUOkJNnw"},"execution_count":null,"outputs":[]}]}